{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Task 1: Importing Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport os\nimport shutil\nimport numpy as np\nimport math\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nfrom platform import python_version\n\nprint('Python version:', python_version())\nprint('Numpy version:', np.__version__)\nprint('Seaborn version:', sns.__version__)\nprint('TensorFlow version:', tf.__version__)\nprint('Is using GPU?', tf.test.is_gpu_available())\n\nfrom distutils.dir_util import copy_tree","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.models import Sequential\nfrom keras_preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Task 2: Dataset Creation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#for Collecting varous animal image data in a singledirectory called \"data\"\nos.mkdir(\"data\")\n\n\n#os.mkdir(\"train_data/\")\n#os.mkdir(\"test_data/\")\n#os.rmdir(\"train_data/\")\n#os.rmdir(\"test_data/\")\n#rm -rf *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#copying all data from different sources to single directory\nfromDirectory=\"../input/african-wildlife/\"\ntoDirectory=\"./data/\"\ncopy_tree(fromDirectory,toDirectory)\nfromDirectory=\"../input/animal-classification/\"\ncopy_tree(fromDirectory,toDirectory)\nfromDirectory=\"../input/cheetahtigerwolf/ANIMAL-N30/ANIMALS/\"\ncopy_tree(fromDirectory,toDirectory)\nfromDirectory=\"../input/cheetahtigerwolf/ANIMALS/ANIMALS/\"\ncopy_tree(fromDirectory,toDirectory)\nfromDirectory=\"../input/animal-detection-small-dataset/train/train/\"\ncopy_tree(fromDirectory,toDirectory)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert names of all sub-directories in our data to lowercase\nimport os\npath='./data/'\nfor file in os.listdir(path):\n    if file!=file.lower():\n        os.rename(path+file,file.lower())\n#after this all the directories whose names were in uppercase gets converted to lowercase and comes outside ./data/ directory.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#copying all the directories from data which were already in lowercase and didn't came outside the ./data/ directory \nfromDirectory=\"./data/\"\ntoDirectory=\"./\"\ncopy_tree(fromDirectory,toDirectory)\n#now all data is been converted to lowercase and are at ./\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#delete all files inside ./data/\nshutil.rmtree('./data/') \nos.remove(\"data.py\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# apply following commands on console:\n# cd ..\n# mkdir data;mv working/* data/;mv data working/;\n# cd working;\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Remove all the redundancy from data manually.\n\"\"\"\ncd data\nls|grep cat\nmv bobcat/* cat/\nmv cats/* cat/\nmv persian+cat/* cat/\nmv siamese+cat/* cat/\nls|grep cat\nrm -rf bobcat/\nls|grep cat\nrm -rf cats\nrm -rf siamese+cat/\nrm -rf persian+cat/\nls|grep cat\nls|grep dog\nmv dogs/* dog\nrmdir dogs\nls|grep dog\nls|grep monk\nmv spider+monkey/* monkey\nls|grep monk\nrmdir spider+monkey\nls|grep monk\nls|grep german\nmv german+shepherd/* dog/\nls|grep german\nrmdir german+shepherd\nls|grep german\nls|grep bear\nmv grizzly+bear/* bear/\nrmdir grizzly+bear\nls|grep bear\nls|grep rhin\nmv rhino/* rhinoceros/\nrmdir rhino\nmv rhino/* rhinoceros/\nls|grep rhin\n\"\"\"\n#or\n# cd data\n# mv bobcat/* cat/;mv cats/* cat/;mv persian+cat/* cat/;mv siamese+cat/* cat/;rm -rf bobcat/;rm -rf cats;rm -rf siamese+cat/;rm -rf persian+cat/;mv dogs/* dog;rmdir dogs;mv spider+monkey/* monkey;rmdir spider+monkey;mv german+shepherd/* dog/;rmdir german+shepherd;mv grizzly+bear/* bear/;rmdir grizzly+bear;mv rhino/* rhinoceros/;rmdir rhino;\n\n# some folders are causing problem so drop them using below cmds:\n# rm -rf hen;rm -rf butterfly;rm -rf spyder;\n\n# cd ..  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create test data set\nos.mkdir(\"test_data\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make dirctories inside test_data with same name as of data\ndata_path='./data/'\ntest_path='./test_data/'\n\nfor name in os.listdir(data_path):\n    os.mkdir(test_path+name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create test_data by taking 25% images from data\n\ntotal_train_images,total_test_images,total_train_classes,total_test_classes=0,0,0,0\npath=\"./data/\"\nfor file in os.listdir(path):\n    if \"notebook\" not in file:\n        total_train_classes+=1\n        total_images=len(os.listdir(path+file+\"/\"))\n        test_image_count=(25/100)*total_images #25% for test and 75% for train\n        for i in range(math.ceil(test_image_count)):\n            img=random.choice(os.listdir(path+file+'/'))\n            shutil.move(path+file+'/'+img,'./test_data/'+file+'/')\n            #print(img)\n        print(file,total_images,math.ceil(test_image_count))\n        total_train_images+=(total_images-math.ceil(test_image_count))\n        #print(file,math.ceil(test_image_count))\nprint(\"total train images are : \",total_train_images,\" and total train classes are : \",total_train_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rename data as train data\n\n# mv data train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# cd test_data\n# rmdir __notebook_source__.ipynb\n# cd ..\n# cd train_data\n# rm -f __notebook_source__.ipynb\n# cd ..","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Total images in train_data = 31104\n#Total images in test_data = 10392","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Task 3: Model Creation"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#inputlayer : apply filters\nmodel.add(Convolution2D(filters=32, \n                        kernel_size=(3,3), \n                        activation='relu',\n                   input_shape=(64, 64, 3)\n                       ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pooling layer where we are doing maxpooling\nmodel.add(MaxPooling2D(pool_size=(2, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding one more convolution layer for better model\nmodel.add(Convolution2D(filters=32, \n                        kernel_size=(3,3), \n                        activation='relu',\n                       ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding one more Pooling layer for better model\nmodel.add(MaxPooling2D(pool_size=(2, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding one more convolution layer for better model\nmodel.add(Convolution2D(filters=32, \n                        kernel_size=(3,3), \n                        activation='relu',\n                       ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding one more Pooling layer for better model\nmodel.add(MaxPooling2D(pool_size=(2, 2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#layer in which we are converting 2d/3d image to 1d image i.e flattening\nmodel.add(Flatten())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# layer: appling relu to give positive output from here our hidden layerrs starts\nmodel.add(Dense(units=256, activation='relu'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# layer: appling relu to give positive output from here our hidden layerrs starts\nmodel.add(Dense(units=128, activation='relu'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# layer: appling relu to give positive output from here our hidden layerrs starts\nmodel.add(Dense(units=64, activation='relu'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# output layer : Since we have to do multi-class classification so we'll apply softmax activation function \n# we have 48 classes of animals so output layer would have that many neurons.\nmodel.add(Dense(units=48, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Task 4: Image Augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#url : https://keras.io/api/preprocessing/image/ \ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntraining_set = train_datagen.flow_from_directory(\n        './train_data/',\n        target_size=(64,64),\n        batch_size=32,\n        class_mode='categorical')\ntest_set = test_datagen.flow_from_directory(\n        './test_data/',\n        target_size=(64,64),\n        batch_size=32,\n        class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_set.class_indices # to see classes of our dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Task 5: Model Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(\n        training_set,\n        steps_per_epoch=(40483/32),\n        epochs=10,\n        validation_data=test_set,\n        validation_steps=(11849/32))\n#Total images in train_data = 40483\n#Total images in test_data = 11849\n#epoch=10","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Task 6: Accuracy"},{"metadata":{"trusted":true},"cell_type":"code","source":"finalAccuracy = history.history[\"accuracy\"]\nfinalAccuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Graphing our training and validation\naccuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'r', label='Training acc')\nplt.plot(epochs, val_accuracy, 'b', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.ylabel('accuracy') \nplt.xlabel('epoch')\nplt.legend()\nplt.figure()\nplt.plot(epochs, loss, 'r', label='Training loss')\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\nplt.title('Training and validation loss')\nplt.ylabel('loss') \nplt.xlabel('epoch')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.save(\"new-cnn-placeimage_model.h5\")#save model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\ntest_image = image.load_img(\"../input/animal-classification/butterfly/butterfly/buttefly.1001.jpeg\",target_size=(64,64))\ntest_image \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image,axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = model.predict(test_image)\n\nmy_dict=training_set.class_indices\ndef get_key(val): \n    for key, value in my_dict.items(): \n         if val == value: \n             return key \n  \n    return \"key doesn't exist\"\n\npred=list(result[0])\nfor i in range(len(pred)):\n    if pred[i]!=0:\n        print(get_key(i))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision.models as models\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import random_split\nfrom torch.utils.data.dataloader import DataLoader\nimport matplotlib.pyplot as plt\n%matplotlib inline\ndataset1 = ImageFolder('./train_data/', transform=ToTensor())\nprint('Size of training dataset :', len(dataset1))\ndataset2 = ImageFolder('./test_data/', transform=ToTensor())\nprint('Size of test dataset :', len(dataset2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}